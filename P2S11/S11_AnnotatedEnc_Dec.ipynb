{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S11_AnnotatedEnc_Dec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soorajkc/EVA4P2/blob/main/P2S11/S11_AnnotatedEnc_Dec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qElzb09OiePe"
      },
      "source": [
        "# ANNOTATED ENCODER-DECODER WITH ATTENTION\n",
        "\n",
        "This is implementation of Neural Language translator(German to English) using Attention Mechnism\n",
        "\n",
        "- Reference: https://bastings.github.io/annotated_encoder_decoder/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85Yt689gGcL4",
        "outputId": "20f115c9-5632-4980-fb4a-0d3735968173",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# mount gdrive\n",
        "mount_drive = True\n",
        "if mount_drive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive') "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H01QY-RKy7GB",
        "outputId": "d38a8242-4021-478f-a257-65f9c1f152fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# check the allocation machine\n",
        "isCuda = torch.cuda.is_available()\n",
        "machine = torch.cuda.get_device_properties(0) if isCuda else 'cpu'\n",
        "print(\"Assigned Machine: \", machine)\n",
        "device = torch.device('cuda:0' if isCuda else 'cpu')\n",
        "print(f\"cuda avaiable: {isCuda}, Device: {device}\")\n",
        "\n",
        "DEVICE = device\n",
        "USE_CUDA = isCuda"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Assigned Machine:  _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15079MB, multi_processor_count=40)\n",
            "cuda avaiable: True, Device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJxS4zcay6-4",
        "outputId": "3458b2c1-e6ad-4c8d-e36d-c592fe18e660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks/EVA4P2/S11/S11_Assign')\n",
        "print(os.getcwd())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/EVA4P2/S11/S11_Assign\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FIuA690y67H"
      },
      "source": [
        "# Import standard packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math, copy, time\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_O3OzAOy628"
      },
      "source": [
        "# To autoreload all te custom files when modified\n",
        "import autoreload\n",
        "%load_ext autoreload\n",
        "%autoreload"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_MJzYydE_nT"
      },
      "source": [
        "import shutil\n",
        "#shutil.rmtree('./logs/logs_tmp')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-3vLC1RAo6x"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# important folders used in this application\n",
        "\n",
        "Path(f'logs').mkdir(exist_ok=True)\n",
        "\n",
        "SOLUTION_LOG_DIR = f\"logs/logs_tmp\"     # root directoy for all the log of this notebook\n",
        "Path(f'./{SOLUTION_LOG_DIR}').mkdir(exist_ok=True)\n",
        "\n",
        "SAVED_MODELS_DIR = Path(f'./{SOLUTION_LOG_DIR}/saved_models') # location to save models\n",
        "SAVED_MODELS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "SAVED_RESULTS_DIR = Path(f'./{SOLUTION_LOG_DIR}/saved_results')\n",
        "SAVED_RESULTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "PLOT_DIR = Path(f'./{SOLUTION_LOG_DIR}/doc_images')\n",
        "PLOT_DIR.mkdir(exist_ok=True)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DAKk6Dp1y9C"
      },
      "source": [
        "# Application specific configurations\n",
        "config_params = dict(\n",
        "    seed=1,\n",
        "    batch_size=64,\n",
        "    num_workers=6,\n",
        "    epochs=100,\n",
        "    upscale_factor=2 \n",
        ")\n",
        "\n",
        "torch.manual_seed(config_params['seed'])\n",
        "if isCuda:\n",
        "   torch.cuda.manual_seed(config_params['seed'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHRZtsVo-Aik"
      },
      "source": [
        "# Model Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm5DLYMf-kHK"
      },
      "source": [
        "## EncoderDecoder Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEq3grlp9qrV"
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A standard Encoder-Decoder architecture. Base for this and many \n",
        "    other models.\n",
        "    \"\"\"\n",
        "    def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.trg_embed = trg_embed\n",
        "        self.generator = generator\n",
        "        \n",
        "    def forward(self, src, trg, src_mask, trg_mask, src_lengths, trg_lengths):\n",
        "        \"\"\"Take in and process masked src and target sequences.\"\"\"\n",
        "        encoder_hidden, encoder_final = self.encode(src, src_mask, src_lengths)\n",
        "        return self.decode(encoder_hidden, encoder_final, src_mask, trg, trg_mask)\n",
        "    \n",
        "    def encode(self, src, src_mask, src_lengths):\n",
        "        return self.encoder(self.src_embed(src), src_mask, src_lengths)\n",
        "    \n",
        "    def decode(self, encoder_hidden, encoder_final, src_mask, trg, trg_mask,\n",
        "               decoder_hidden=None):\n",
        "        return self.decoder(self.trg_embed(trg), encoder_hidden, encoder_final,\n",
        "                            src_mask, trg_mask, hidden=decoder_hidden)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWBouWOV-K1C"
      },
      "source": [
        "## Generator\n",
        "\n",
        "**Generator class simply projects the pre-output layer (x in the forward function below) to obtain the output layer, so that the final dimension is the target vocabulary size.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL1LXJsT9q0j"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"Define standard linear + softmax generation step.\"\"\"\n",
        "    def __init__(self, hidden_size, vocab_size):\n",
        "        super(Generator, self).__init__()\n",
        "        self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.proj(x), dim=-1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBoPPpC6-SQg"
      },
      "source": [
        "## Encoder\n",
        "\n",
        "Encoder is bi-directional GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugj6La2q9q6B"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"Encodes a sequence of word embeddings\"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.GRU(input_size, hidden_size, num_layers, \n",
        "                          batch_first=True, bidirectional=True, dropout=dropout)\n",
        "        \n",
        "    def forward(self, x, mask, lengths):\n",
        "        \"\"\"\n",
        "        Applies a bidirectional GRU to sequence of embeddings x.\n",
        "        The input mini-batch x needs to be sorted by length.\n",
        "        x should have dimensions [batch, time, dim].\n",
        "        \"\"\"\n",
        "        packed = pack_padded_sequence(x, lengths, batch_first=True)\n",
        "        output, final = self.rnn(packed)\n",
        "        output, _ = pad_packed_sequence(output, batch_first=True)\n",
        "\n",
        "        # we need to manually concatenate the final states for both directions\n",
        "        fwd_final = final[0:final.size(0):2]\n",
        "        bwd_final = final[1:final.size(0):2]\n",
        "        final = torch.cat([fwd_final, bwd_final], dim=2)  # [num_layers, batch, 2*dim]\n",
        "\n",
        "        return output, final"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ5m3uQz-r30"
      },
      "source": [
        "## Decoder\n",
        "The decoder is a conditional GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R46WQIfT9rEj"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"A conditional RNN decoder with attention.\"\"\"\n",
        "    \n",
        "    def __init__(self, emb_size, hidden_size, attention, num_layers=1, dropout=0.5,\n",
        "                 bridge=True):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.attention = attention\n",
        "        self.dropout = dropout\n",
        "                 \n",
        "        self.rnn = nn.GRU(emb_size + 2*hidden_size, hidden_size, num_layers,\n",
        "                          batch_first=True, dropout=dropout)\n",
        "                 \n",
        "        # to initialize from the final encoder state\n",
        "        self.bridge = nn.Linear(2*hidden_size, hidden_size, bias=True) if bridge else None\n",
        "\n",
        "        self.dropout_layer = nn.Dropout(p=dropout)\n",
        "        self.pre_output_layer = nn.Linear(hidden_size + 2*hidden_size + emb_size,\n",
        "                                          hidden_size, bias=False)\n",
        "        \n",
        "    def forward_step(self, prev_embed, encoder_hidden, src_mask, proj_key, hidden):\n",
        "        \"\"\"Perform a single decoder step (1 word)\"\"\"\n",
        "\n",
        "        # compute context vector using attention mechanism\n",
        "        query = hidden[-1].unsqueeze(1)  # [#layers, B, D] -> [B, 1, D]\n",
        "        context, attn_probs = self.attention(\n",
        "            query=query, proj_key=proj_key,\n",
        "            value=encoder_hidden, mask=src_mask)\n",
        "\n",
        "        # update rnn hidden state\n",
        "        rnn_input = torch.cat([prev_embed, context], dim=2)\n",
        "        output, hidden = self.rnn(rnn_input, hidden)\n",
        "        \n",
        "        pre_output = torch.cat([prev_embed, output, context], dim=2)\n",
        "        pre_output = self.dropout_layer(pre_output)\n",
        "        pre_output = self.pre_output_layer(pre_output)\n",
        "\n",
        "        return output, hidden, pre_output\n",
        "    \n",
        "    def forward(self, trg_embed, encoder_hidden, encoder_final, \n",
        "                src_mask, trg_mask, hidden=None, max_len=None):\n",
        "        \"\"\"Unroll the decoder one step at a time.\"\"\"\n",
        "                                         \n",
        "        # the maximum number of steps to unroll the RNN\n",
        "        if max_len is None:\n",
        "            max_len = trg_mask.size(-1)\n",
        "\n",
        "        # initialize decoder hidden state\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(encoder_final)\n",
        "        \n",
        "        # pre-compute projected encoder hidden states\n",
        "        # (the \"keys\" for the attention mechanism)\n",
        "        # this is only done for efficiency\n",
        "        proj_key = self.attention.key_layer(encoder_hidden)\n",
        "        \n",
        "        # here we store all intermediate hidden states and pre-output vectors\n",
        "        decoder_states = []\n",
        "        pre_output_vectors = []\n",
        "        \n",
        "        # unroll the decoder RNN for max_len steps\n",
        "        for i in range(max_len):\n",
        "            prev_embed = trg_embed[:, i].unsqueeze(1)\n",
        "            output, hidden, pre_output = self.forward_step(\n",
        "              prev_embed, encoder_hidden, src_mask, proj_key, hidden)\n",
        "            decoder_states.append(output)\n",
        "            pre_output_vectors.append(pre_output)\n",
        "\n",
        "        decoder_states = torch.cat(decoder_states, dim=1)\n",
        "        pre_output_vectors = torch.cat(pre_output_vectors, dim=1)\n",
        "        return decoder_states, hidden, pre_output_vectors  # [B, N, D]\n",
        "\n",
        "    def init_hidden(self, encoder_final):\n",
        "        \"\"\"Returns the initial decoder state,\n",
        "        conditioned on the final encoder state.\"\"\"\n",
        "\n",
        "        if encoder_final is None:\n",
        "            return None  # start with zeros\n",
        "\n",
        "        return torch.tanh(self.bridge(encoder_final))   "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zagZcZLM_GU1"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzosGTFo9rR6"
      },
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    \"\"\"Implements Bahdanau (MLP) attention\"\"\"\n",
        "    \n",
        "    def __init__(self, hidden_size, key_size=None, query_size=None):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        \n",
        "        # We assume a bi-directional encoder so key_size is 2*hidden_size\n",
        "        key_size = 2 * hidden_size if key_size is None else key_size\n",
        "        query_size = hidden_size if query_size is None else query_size\n",
        "\n",
        "        self.key_layer = nn.Linear(key_size, hidden_size, bias=False)\n",
        "        self.query_layer = nn.Linear(query_size, hidden_size, bias=False)\n",
        "        self.energy_layer = nn.Linear(hidden_size, 1, bias=False)\n",
        "        \n",
        "        # to store attention scores\n",
        "        self.alphas = None\n",
        "        \n",
        "    def forward(self, query=None, proj_key=None, value=None, mask=None):\n",
        "        assert mask is not None, \"mask is required\"\n",
        "\n",
        "        # We first project the query (the decoder state).\n",
        "        # The projected keys (the encoder states) were already pre-computated.\n",
        "        query = self.query_layer(query)\n",
        "        \n",
        "        # Calculate scores.\n",
        "        scores = self.energy_layer(torch.tanh(query + proj_key))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "        \n",
        "        # Mask out invalid positions.\n",
        "        # The mask marks valid positions so we invert it using `mask & 0`.\n",
        "        scores.data.masked_fill_(mask == 0, -float('inf'))\n",
        "        \n",
        "        # Turn scores to probabilities.\n",
        "        alphas = F.softmax(scores, dim=-1)\n",
        "        self.alphas = alphas        \n",
        "        \n",
        "        # The context vector is the weighted sum of the values.\n",
        "        context = torch.bmm(alphas, value)\n",
        "        \n",
        "        # context shape: [B, 1, 2D], alphas shape: [B, 1, M]\n",
        "        return context, alphas"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ugV3MKg_ZOq"
      },
      "source": [
        "## Full Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIWUl5lv9rPB"
      },
      "source": [
        "def make_model(src_vocab, tgt_vocab, emb_size=256, hidden_size=512, num_layers=1, dropout=0.1):\n",
        "    \"Helper: Construct a model from hyperparameters.\"\n",
        "\n",
        "    attention = BahdanauAttention(hidden_size)\n",
        "\n",
        "    model = EncoderDecoder(\n",
        "        Encoder(emb_size, hidden_size, num_layers=num_layers, dropout=dropout),\n",
        "        Decoder(emb_size, hidden_size, attention, num_layers=num_layers, dropout=dropout),\n",
        "        nn.Embedding(src_vocab, emb_size),\n",
        "        nn.Embedding(tgt_vocab, emb_size),\n",
        "        Generator(hidden_size, tgt_vocab))\n",
        "\n",
        "    return model.cuda() if USE_CUDA else model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6PkRunb_y1T"
      },
      "source": [
        "# Traning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJFi3H8T__eL"
      },
      "source": [
        "## Batches and Masking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiW4sHPe9rMH"
      },
      "source": [
        "class Batch:\n",
        "    \"\"\"Object for holding a batch of data with mask during training.\n",
        "    Input is a batch from a torch text iterator.\n",
        "    \"\"\"\n",
        "    def __init__(self, src, trg, pad_index=0):\n",
        "        \n",
        "        src, src_lengths = src\n",
        "        \n",
        "        self.src = src\n",
        "        self.src_lengths = src_lengths\n",
        "        self.src_mask = (src != pad_index).unsqueeze(-2)\n",
        "        self.nseqs = src.size(0)\n",
        "        \n",
        "        self.trg = None\n",
        "        self.trg_y = None\n",
        "        self.trg_mask = None\n",
        "        self.trg_lengths = None\n",
        "        self.ntokens = None\n",
        "\n",
        "        if trg is not None:\n",
        "            trg, trg_lengths = trg\n",
        "            self.trg = trg[:, :-1]\n",
        "            self.trg_lengths = trg_lengths\n",
        "            self.trg_y = trg[:, 1:]\n",
        "            self.trg_mask = (self.trg_y != pad_index)\n",
        "            self.ntokens = (self.trg_y != pad_index).data.sum().item()\n",
        "        \n",
        "        if USE_CUDA:\n",
        "            self.src = self.src.cuda()\n",
        "            self.src_mask = self.src_mask.cuda()\n",
        "\n",
        "            if trg is not None:\n",
        "                self.trg = self.trg.cuda()\n",
        "                self.trg_y = self.trg_y.cuda()\n",
        "                self.trg_mask = self.trg_mask.cuda()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qREeX76KAFB7"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIPnDWdX9rJK"
      },
      "source": [
        "def run_epoch(data_iter, model, loss_compute, print_every=50):\n",
        "    \"\"\"Standard Training and Logging Function\"\"\"\n",
        "\n",
        "    start = time.time()\n",
        "    total_tokens = 0\n",
        "    total_loss = 0\n",
        "    print_tokens = 0\n",
        "\n",
        "    for i, batch in enumerate(data_iter, 1):\n",
        "        \n",
        "        out, _, pre_output = model.forward(batch.src, batch.trg,\n",
        "                                           batch.src_mask, batch.trg_mask,\n",
        "                                           batch.src_lengths, batch.trg_lengths)\n",
        "        loss = loss_compute(pre_output, batch.trg_y, batch.nseqs)\n",
        "        total_loss += loss\n",
        "        total_tokens += batch.ntokens\n",
        "        print_tokens += batch.ntokens\n",
        "        \n",
        "        if model.training and i % print_every == 0:\n",
        "            elapsed = time.time() - start\n",
        "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n",
        "                    (i, loss / batch.nseqs, print_tokens / elapsed))\n",
        "            start = time.time()\n",
        "            print_tokens = 0\n",
        "\n",
        "    return math.exp(total_loss / float(total_tokens))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcLMssUhA937"
      },
      "source": [
        "# IWSLT German-English Translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqvHj15bBFXb",
        "outputId": "ca16db3d-35b9-4305-8ead-cef3962a8ca0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#!pip install git+git://github.com/pytorch/text spacy \n",
        "#!python -m spacy download en\n",
        "#!python -m spacy download de"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/pytorch/text\n",
            "  Cloning git://github.com/pytorch/text to /tmp/pip-req-build-z069dixl\n",
            "  Running command git clone -q git://github.com/pytorch/text /tmp/pip-req-build-z069dixl\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+97e6d1d) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+97e6d1d) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+97e6d1d) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+97e6d1d) (1.18.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+97e6d1d) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+97e6d1d) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+97e6d1d) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+97e6d1d) (2.10)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.9.0a0+97e6d1d) (0.16.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.3.1)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Building wheel for torchtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchtext: filename=torchtext-0.9.0a0+97e6d1d-cp36-cp36m-linux_x86_64.whl size=6978791 sha256=b313e4e21e1782245dd882d55ff42f3e7f38f4049b8bb5f62ff51fb47c490950\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q478ewmv/wheels/39/42/ff/82f5ccbb0f30b25e14610376f5d0c67913fc05017dab59f8eb\n",
            "Successfully built torchtext\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed torchtext-0.9.0a0+97e6d1d\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.3.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 16.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.3.1)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907056 sha256=ec69e9028d1df18152fa878be0f4fdfb6e31c87337b489acf069adcd840c4162\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p18ukd1e/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOfyiB0dGYhM"
      },
      "source": [
        "## Loss Computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELcWC3ZYGflM"
      },
      "source": [
        "class SimpleLossCompute:\n",
        "    \"\"\"A simple loss compute and train function.\"\"\"\n",
        "\n",
        "    def __init__(self, generator, criterion, opt=None):\n",
        "        self.generator = generator\n",
        "        self.criterion = criterion\n",
        "        self.opt = opt\n",
        "\n",
        "    def __call__(self, x, y, norm):\n",
        "        x = self.generator(x)\n",
        "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)),\n",
        "                              y.contiguous().view(-1))\n",
        "        loss = loss / norm\n",
        "\n",
        "        if self.opt is not None:\n",
        "            loss.backward()          \n",
        "            self.opt.step()\n",
        "            self.opt.zero_grad()\n",
        "\n",
        "        return loss.data.item() * norm"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKUPhST4KMCk"
      },
      "source": [
        "## Printing Functions\n",
        "\n",
        "To monitor progress during training, we will translate a few examples.\n",
        "\n",
        "We use greedy decoding for simplicity; that is, at each time step, starting at the first token, we choose the one with that maximum probability, and we never revisit that choice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9H_KnQeKPY_"
      },
      "source": [
        "def greedy_decode(model, src, src_mask, src_lengths, max_len=100, sos_index=1, eos_index=None):\n",
        "    \"\"\"Greedily decode a sentence.\"\"\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_hidden, encoder_final = model.encode(src, src_mask, src_lengths)\n",
        "        prev_y = torch.ones(1, 1).fill_(sos_index).type_as(src)\n",
        "        trg_mask = torch.ones_like(prev_y)\n",
        "\n",
        "    output = []\n",
        "    attention_scores = []\n",
        "    hidden = None\n",
        "\n",
        "    for i in range(max_len):\n",
        "        with torch.no_grad():\n",
        "            out, hidden, pre_output = model.decode(\n",
        "              encoder_hidden, encoder_final, src_mask,\n",
        "              prev_y, trg_mask, hidden)\n",
        "\n",
        "            # we predict from the pre-output layer, which is\n",
        "            # a combination of Decoder state, prev emb, and context\n",
        "            prob = model.generator(pre_output[:, -1])\n",
        "\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.data.item()\n",
        "        output.append(next_word)\n",
        "        prev_y = torch.ones(1, 1).type_as(src).fill_(next_word)\n",
        "        attention_scores.append(model.decoder.attention.alphas.cpu().numpy())\n",
        "    \n",
        "    output = np.array(output)\n",
        "        \n",
        "    # cut off everything starting from </s> \n",
        "    # (only when eos_index provided)\n",
        "    if eos_index is not None:\n",
        "        first_eos = np.where(output==eos_index)[0]\n",
        "        if len(first_eos) > 0:\n",
        "            output = output[:first_eos[0]]      \n",
        "    \n",
        "    return output, np.concatenate(attention_scores, axis=1)\n",
        "  \n",
        "\n",
        "def lookup_words(x, vocab=None):\n",
        "    if vocab is not None:\n",
        "        x = [vocab.itos[i] for i in x]\n",
        "\n",
        "    return [str(t) for t in x]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9voFLWQKPiY"
      },
      "source": [
        "def print_examples(example_iter, model, n=2, max_len=100, \n",
        "                   sos_index=1, \n",
        "                   src_eos_index=None, \n",
        "                   trg_eos_index=None, \n",
        "                   src_vocab=None, trg_vocab=None):\n",
        "    \"\"\"Prints N examples. Assumes batch size of 1.\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    count = 0\n",
        "    print()\n",
        "    \n",
        "    if src_vocab is not None and trg_vocab is not None:\n",
        "        src_eos_index = src_vocab.stoi[EOS_TOKEN]\n",
        "        trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n",
        "        trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n",
        "    else:\n",
        "        src_eos_index = None\n",
        "        trg_sos_index = 1\n",
        "        trg_eos_index = None\n",
        "        \n",
        "    for i, batch in enumerate(example_iter):\n",
        "      \n",
        "        src = batch.src.cpu().numpy()[0, :]\n",
        "        trg = batch.trg_y.cpu().numpy()[0, :]\n",
        "\n",
        "        # remove </s> (if it is there)\n",
        "        src = src[:-1] if src[-1] == src_eos_index else src\n",
        "        trg = trg[:-1] if trg[-1] == trg_eos_index else trg      \n",
        "      \n",
        "        result, _ = greedy_decode(\n",
        "          model, batch.src, batch.src_mask, batch.src_lengths,\n",
        "          max_len=max_len, sos_index=trg_sos_index, eos_index=trg_eos_index)\n",
        "        print(\"Example #%d\" % (i+1))\n",
        "        print(\"Src : \", \" \".join(lookup_words(src, vocab=src_vocab)))\n",
        "        print(\"Trg : \", \" \".join(lookup_words(trg, vocab=trg_vocab)))\n",
        "        print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab)))\n",
        "        print()\n",
        "        \n",
        "        count += 1\n",
        "        if count == n:\n",
        "            break"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M8eOLUWLl4I"
      },
      "source": [
        "def plot_perplexity(perplexities):\n",
        "    \"\"\"plot perplexities\"\"\"\n",
        "    plt.title(\"Perplexity per Epoch\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Perplexity\")\n",
        "    plt.plot(perplexities)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lj-lpNnBBOG"
      },
      "source": [
        "## Date loading\n",
        "\n",
        "load the dataset using torchtext and spacy for tokenization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQAvoRRuAJ0b",
        "outputId": "0f0e46b3-1647-462b-948d-9f5827c35e52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# For data loading.\n",
        "from torchtext import data, datasets\n",
        "\n",
        "if True:\n",
        "    import spacy\n",
        "    spacy_de = spacy.load('de')\n",
        "    spacy_en = spacy.load('en')\n",
        "\n",
        "    def tokenize_de(text):\n",
        "        return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "    def tokenize_en(text):\n",
        "        return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "    UNK_TOKEN = \"<unk>\"\n",
        "    PAD_TOKEN = \"<pad>\"    \n",
        "    SOS_TOKEN = \"<s>\"\n",
        "    EOS_TOKEN = \"</s>\"\n",
        "    LOWER = True\n",
        "    \n",
        "    # we include lengths to provide to the RNNs\n",
        "    SRC = data.Field(tokenize=tokenize_de, \n",
        "                     batch_first=True, lower=LOWER, include_lengths=True,\n",
        "                     unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=None, eos_token=EOS_TOKEN)\n",
        "    TRG = data.Field(tokenize=tokenize_en, \n",
        "                     batch_first=True, lower=LOWER, include_lengths=True,\n",
        "                     unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=SOS_TOKEN, eos_token=EOS_TOKEN)\n",
        "\n",
        "    MAX_LEN = 25  # NOTE: we filter out a lot of sentences for speed\n",
        "    train_data, valid_data, test_data = datasets.IWSLT.splits(\n",
        "        exts=('.de', '.en'), fields=(SRC, TRG), \n",
        "        filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
        "            len(vars(x)['trg']) <= MAX_LEN)\n",
        "    MIN_FREQ = 5  # NOTE: we limit the vocabulary to frequent words for speed\n",
        "    SRC.build_vocab(train_data.src, min_freq=MIN_FREQ)\n",
        "    TRG.build_vocab(train_data.trg, min_freq=MIN_FREQ)\n",
        "    \n",
        "    PAD_INDEX = TRG.vocab.stoi[PAD_TOKEN]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading de-en.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "de-en.tgz: 100%|██████████| 24.2M/24.2M [00:05<00:00, 4.57MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".data/iwslt/de-en/IWSLT16.TED.dev2010.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.dev2010.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2010.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2010.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2011.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2011.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2012.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2012.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2013.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2013.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2014.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2014.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.dev2012.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.dev2012.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2013.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2013.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2014.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2014.de-en.en.xml\n",
            ".data/iwslt/de-en/train.tags.de-en.de\n",
            ".data/iwslt/de-en/train.tags.de-en.en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfJWf1Q7BU-q"
      },
      "source": [
        "Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmwioqYIAKBg",
        "outputId": "4363dca8-4f37-4e8d-a2c2-ccc4ea2e885d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def print_data_info(train_data, valid_data, test_data, src_field, trg_field):\n",
        "    \"\"\" This prints some useful stuff about our data sets. \"\"\"\n",
        "\n",
        "    print(\"Data set sizes (number of sentence pairs):\")\n",
        "    print('train', len(train_data))\n",
        "    print('valid', len(valid_data))\n",
        "    print('test', len(test_data), \"\\n\")\n",
        "\n",
        "    print(\"First training example:\")\n",
        "    print(\"src:\", \" \".join(vars(train_data[0])['src']))\n",
        "    print(\"trg:\", \" \".join(vars(train_data[0])['trg']), \"\\n\")\n",
        "\n",
        "    print(\"Most common words (src):\")\n",
        "    print(\"\\n\".join([\"%10s %10d\" % x for x in src_field.vocab.freqs.most_common(10)]), \"\\n\")\n",
        "    print(\"Most common words (trg):\")\n",
        "    print(\"\\n\".join([\"%10s %10d\" % x for x in trg_field.vocab.freqs.most_common(10)]), \"\\n\")\n",
        "\n",
        "    print(\"First 10 words (src):\")\n",
        "    print(\"\\n\".join(\n",
        "        '%02d %s' % (i, t) for i, t in enumerate(src_field.vocab.itos[:10])), \"\\n\")\n",
        "    print(\"First 10 words (trg):\")\n",
        "    print(\"\\n\".join(\n",
        "        '%02d %s' % (i, t) for i, t in enumerate(trg_field.vocab.itos[:10])), \"\\n\")\n",
        "\n",
        "    print(\"Number of German words (types):\", len(src_field.vocab))\n",
        "    print(\"Number of English words (types):\", len(trg_field.vocab), \"\\n\")\n",
        "    \n",
        "    \n",
        "print_data_info(train_data, valid_data, test_data, SRC, TRG)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data set sizes (number of sentence pairs):\n",
            "train 143115\n",
            "valid 690\n",
            "test 963 \n",
            "\n",
            "First training example:\n",
            "src: david gallo : das ist bill lange . ich bin dave gallo .\n",
            "trg: david gallo : this is bill lange . i 'm dave gallo . \n",
            "\n",
            "Most common words (src):\n",
            "         .     138329\n",
            "         ,     105944\n",
            "       und      41843\n",
            "       die      40808\n",
            "       das      33324\n",
            "       sie      33034\n",
            "       ich      31150\n",
            "       ist      31037\n",
            "        es      27449\n",
            "       wir      25817 \n",
            "\n",
            "Most common words (trg):\n",
            "         .     137259\n",
            "         ,      91615\n",
            "       the      73343\n",
            "       and      50276\n",
            "        to      42799\n",
            "         a      39572\n",
            "        of      39496\n",
            "         i      33521\n",
            "        it      32920\n",
            "      that      32640 \n",
            "\n",
            "First 10 words (src):\n",
            "00 <unk>\n",
            "01 <pad>\n",
            "02 </s>\n",
            "03 .\n",
            "04 ,\n",
            "05 und\n",
            "06 die\n",
            "07 das\n",
            "08 sie\n",
            "09 ich \n",
            "\n",
            "First 10 words (trg):\n",
            "00 <unk>\n",
            "01 <pad>\n",
            "02 <s>\n",
            "03 </s>\n",
            "04 .\n",
            "05 ,\n",
            "06 the\n",
            "07 and\n",
            "08 to\n",
            "09 a \n",
            "\n",
            "Number of German words (types): 15765\n",
            "Number of English words (types): 13002 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1ple9-0AKFh"
      },
      "source": [
        "train_iter = data.BucketIterator(train_data, batch_size=64, train=True, \n",
        "                                 sort_within_batch=True, \n",
        "                                 sort_key=lambda x: (len(x.src), len(x.trg)), repeat=False,\n",
        "                                 device=DEVICE)\n",
        "valid_iter = data.Iterator(valid_data, batch_size=1, train=False, sort=False, repeat=False, \n",
        "                           device=DEVICE)\n",
        "\n",
        "\n",
        "def rebatch(pad_idx, batch):\n",
        "    \"\"\"Wrap torchtext batch into our own Batch class for pre-processing\"\"\"\n",
        "    return Batch(batch.src, batch.trg, pad_idx)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRbIPY2QBghu"
      },
      "source": [
        "## Training the System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p37GkR1oBf7A"
      },
      "source": [
        "def train(model, num_epochs=10, lr=0.0003, print_every=100):\n",
        "    \"\"\"Train a model on IWSLT\"\"\"\n",
        "    \n",
        "    if USE_CUDA:\n",
        "        model.cuda()\n",
        "\n",
        "    # optionally add label smoothing; see the Annotated Transformer\n",
        "    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    dev_perplexities = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      \n",
        "        print(\"Epoch\", epoch)\n",
        "        model.train()\n",
        "        train_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in train_iter), \n",
        "                                     model,\n",
        "                                     SimpleLossCompute(model.generator, criterion, optim),\n",
        "                                     print_every=print_every)\n",
        "        \n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            print_examples((rebatch(PAD_INDEX, x) for x in valid_iter), \n",
        "                           model, n=3, src_vocab=SRC.vocab, trg_vocab=TRG.vocab)        \n",
        "\n",
        "            dev_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in valid_iter), \n",
        "                                       model, \n",
        "                                       SimpleLossCompute(model.generator, criterion, None))\n",
        "            print(\"Validation perplexity: %f\" % dev_perplexity)\n",
        "            dev_perplexities.append(dev_perplexity)\n",
        "        \n",
        "    return dev_perplexities"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeObS7ObBgFI",
        "outputId": "008b7b21-d354-4bd1-e6b3-03fb6f8f5ea8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = make_model(len(SRC.vocab), len(TRG.vocab),\n",
        "                   emb_size=256, hidden_size=256,\n",
        "                   num_layers=1, dropout=0.2)\n",
        "dev_perplexities = train(model, num_epochs=10, print_every=200)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Epoch Step: 200 Loss: 131.045898 Tokens per Sec: 22555.816964\n",
            "Epoch Step: 400 Loss: 58.186974 Tokens per Sec: 23343.322856\n",
            "Epoch Step: 600 Loss: 43.433563 Tokens per Sec: 23146.816994\n",
            "Epoch Step: 800 Loss: 54.407608 Tokens per Sec: 23450.773330\n",
            "Epoch Step: 1000 Loss: 34.287407 Tokens per Sec: 23892.023625\n",
            "Epoch Step: 1200 Loss: 22.035604 Tokens per Sec: 23943.031089\n",
            "Epoch Step: 1400 Loss: 55.183762 Tokens per Sec: 23939.338113\n",
            "Epoch Step: 1600 Loss: 58.919945 Tokens per Sec: 23859.687778\n",
            "Epoch Step: 1800 Loss: 38.972099 Tokens per Sec: 24094.631252\n",
            "Epoch Step: 2000 Loss: 84.383728 Tokens per Sec: 23877.284802\n",
            "Epoch Step: 2200 Loss: 76.801735 Tokens per Sec: 23938.902311\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was eight years old , i was a little bit of the <unk> of the <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father was on the <unk> , the <unk> , the <unk> of the <unk> .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he was very excited , what was pretty much was a very little bit of him , there was him .\n",
            "\n",
            "Validation perplexity: 31.280246\n",
            "Epoch 1\n",
            "Epoch Step: 200 Loss: 82.405251 Tokens per Sec: 23179.859501\n",
            "Epoch Step: 400 Loss: 79.365547 Tokens per Sec: 23891.047580\n",
            "Epoch Step: 600 Loss: 31.927298 Tokens per Sec: 24121.808117\n",
            "Epoch Step: 800 Loss: 78.223534 Tokens per Sec: 24081.908851\n",
            "Epoch Step: 1000 Loss: 19.634306 Tokens per Sec: 23966.438916\n",
            "Epoch Step: 1200 Loss: 29.957872 Tokens per Sec: 23930.935097\n",
            "Epoch Step: 1400 Loss: 48.721596 Tokens per Sec: 23828.920966\n",
            "Epoch Step: 1600 Loss: 84.696701 Tokens per Sec: 23687.631650\n",
            "Epoch Step: 1800 Loss: 80.433105 Tokens per Sec: 23577.309455\n",
            "Epoch Step: 2000 Loss: 62.319431 Tokens per Sec: 23794.603592\n",
            "Epoch Step: 2200 Loss: 49.915699 Tokens per Sec: 23693.323333\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a <unk> of the <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father was <unk> on his little , the <unk> of the <unk> .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was pretty much , because it was <unk> .\n",
            "\n",
            "Validation perplexity: 19.980845\n",
            "Epoch 2\n",
            "Epoch Step: 200 Loss: 43.806858 Tokens per Sec: 23342.610013\n",
            "Epoch Step: 400 Loss: 70.557945 Tokens per Sec: 24070.078898\n",
            "Epoch Step: 600 Loss: 44.910603 Tokens per Sec: 23810.502574\n",
            "Epoch Step: 800 Loss: 20.194653 Tokens per Sec: 23846.510835\n",
            "Epoch Step: 1000 Loss: 44.640984 Tokens per Sec: 24021.911191\n",
            "Epoch Step: 1200 Loss: 67.353310 Tokens per Sec: 23816.238424\n",
            "Epoch Step: 1400 Loss: 55.102242 Tokens per Sec: 23804.890301\n",
            "Epoch Step: 1600 Loss: 38.805164 Tokens per Sec: 24056.627397\n",
            "Epoch Step: 1800 Loss: 32.448135 Tokens per Sec: 23820.490914\n",
            "Epoch Step: 2000 Loss: 15.383624 Tokens per Sec: 23681.851255\n",
            "Epoch Step: 2200 Loss: 13.757680 Tokens per Sec: 23754.171487\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a <unk> of the <unk> <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father was on his little , <unk> , the <unk> of the <unk> of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was pretty much of it , it was the <unk> of the <unk> .\n",
            "\n",
            "Validation perplexity: 15.496886\n",
            "Epoch 3\n",
            "Epoch Step: 200 Loss: 30.590239 Tokens per Sec: 23380.153215\n",
            "Epoch Step: 400 Loss: 23.859024 Tokens per Sec: 23955.766735\n",
            "Epoch Step: 600 Loss: 28.189585 Tokens per Sec: 23914.070340\n",
            "Epoch Step: 800 Loss: 65.737663 Tokens per Sec: 23862.693094\n",
            "Epoch Step: 1000 Loss: 57.087753 Tokens per Sec: 23330.492271\n",
            "Epoch Step: 1200 Loss: 17.364143 Tokens per Sec: 23337.500300\n",
            "Epoch Step: 1400 Loss: 68.321533 Tokens per Sec: 23638.873491\n",
            "Epoch Step: 1600 Loss: 34.234142 Tokens per Sec: 23840.353134\n",
            "Epoch Step: 1800 Loss: 23.101019 Tokens per Sec: 23989.433778\n",
            "Epoch Step: 2000 Loss: 30.227514 Tokens per Sec: 23891.627903\n",
            "Epoch Step: 2200 Loss: 35.307823 Tokens per Sec: 23938.825132\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a <unk> of the <unk> <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my dad was <unk> on his little , <unk> radio <unk> .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was pretty much unusual , because it was <unk> the <unk> of <unk> .\n",
            "\n",
            "Validation perplexity: 13.475346\n",
            "Epoch 4\n",
            "Epoch Step: 200 Loss: 5.481750 Tokens per Sec: 23011.046191\n",
            "Epoch Step: 400 Loss: 44.055515 Tokens per Sec: 23679.362189\n",
            "Epoch Step: 600 Loss: 20.254871 Tokens per Sec: 23872.111137\n",
            "Epoch Step: 800 Loss: 23.779835 Tokens per Sec: 23979.615812\n",
            "Epoch Step: 1000 Loss: 15.243543 Tokens per Sec: 23947.439946\n",
            "Epoch Step: 1200 Loss: 24.001362 Tokens per Sec: 23517.283316\n",
            "Epoch Step: 1400 Loss: 42.408100 Tokens per Sec: 23705.243858\n",
            "Epoch Step: 1600 Loss: 15.940285 Tokens per Sec: 23479.081109\n",
            "Epoch Step: 1800 Loss: 6.076687 Tokens per Sec: 23765.664053\n",
            "Epoch Step: 2000 Loss: 32.359383 Tokens per Sec: 23869.410844\n",
            "Epoch Step: 2200 Loss: 3.008107 Tokens per Sec: 23735.525844\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years , i became a <unk> of the <unk> <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father stopped <unk> , his <unk> , the <unk> of the bbc of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was very unusual , because it was <unk> the news of <unk> .\n",
            "\n",
            "Validation perplexity: 12.615999\n",
            "Epoch 5\n",
            "Epoch Step: 200 Loss: 57.418503 Tokens per Sec: 23098.138738\n",
            "Epoch Step: 400 Loss: 34.418823 Tokens per Sec: 23514.381786\n",
            "Epoch Step: 600 Loss: 56.320484 Tokens per Sec: 23454.277350\n",
            "Epoch Step: 800 Loss: 57.254379 Tokens per Sec: 23394.591795\n",
            "Epoch Step: 1000 Loss: 41.660225 Tokens per Sec: 23518.580618\n",
            "Epoch Step: 1200 Loss: 54.737736 Tokens per Sec: 23851.419735\n",
            "Epoch Step: 1400 Loss: 22.480679 Tokens per Sec: 23896.957138\n",
            "Epoch Step: 1600 Loss: 57.045815 Tokens per Sec: 23567.898246\n",
            "Epoch Step: 1800 Loss: 43.055733 Tokens per Sec: 23800.990166\n",
            "Epoch Step: 2000 Loss: 26.502914 Tokens per Sec: 23464.890983\n",
            "Epoch Step: 2200 Loss: 19.825512 Tokens per Sec: 23877.078884\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years , i was <unk> one of the <unk> of joy .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father stopped <unk> , his radio shack on the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was pretty awful for him , it was <unk> the <unk> of the <unk> .\n",
            "\n",
            "Validation perplexity: 12.248126\n",
            "Epoch 6\n",
            "Epoch Step: 200 Loss: 9.454590 Tokens per Sec: 23022.899865\n",
            "Epoch Step: 400 Loss: 45.300892 Tokens per Sec: 23338.834827\n",
            "Epoch Step: 600 Loss: 39.368099 Tokens per Sec: 23601.245577\n",
            "Epoch Step: 800 Loss: 55.940929 Tokens per Sec: 23787.312213\n",
            "Epoch Step: 1000 Loss: 6.628642 Tokens per Sec: 23830.328766\n",
            "Epoch Step: 1200 Loss: 14.562707 Tokens per Sec: 23656.832686\n",
            "Epoch Step: 1400 Loss: 16.268797 Tokens per Sec: 23473.024378\n",
            "Epoch Step: 1600 Loss: 55.353775 Tokens per Sec: 23350.542537\n",
            "Epoch Step: 1800 Loss: 38.156582 Tokens per Sec: 23681.086752\n",
            "Epoch Step: 2000 Loss: 7.235240 Tokens per Sec: 23756.236347\n",
            "Epoch Step: 2200 Loss: 41.785229 Tokens per Sec: 23897.826419\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years , i was <unk> one of the other things that joy .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father was <unk> on his little , gray radio shack the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he looked very happy , which was pretty much unusual , that was the news of the news mostly <unk> .\n",
            "\n",
            "Validation perplexity: 11.875892\n",
            "Epoch 7\n",
            "Epoch Step: 200 Loss: 33.867592 Tokens per Sec: 22950.932405\n",
            "Epoch Step: 400 Loss: 16.235193 Tokens per Sec: 23584.785910\n",
            "Epoch Step: 600 Loss: 25.435717 Tokens per Sec: 23681.004031\n",
            "Epoch Step: 800 Loss: 7.906111 Tokens per Sec: 23569.698106\n",
            "Epoch Step: 1000 Loss: 23.898699 Tokens per Sec: 23877.464149\n",
            "Epoch Step: 1200 Loss: 55.728806 Tokens per Sec: 23714.540949\n",
            "Epoch Step: 1400 Loss: 54.222538 Tokens per Sec: 23812.877888\n",
            "Epoch Step: 1600 Loss: 53.499420 Tokens per Sec: 23996.929668\n",
            "Epoch Step: 1800 Loss: 41.723698 Tokens per Sec: 23768.191071\n",
            "Epoch Step: 2000 Loss: 37.692810 Tokens per Sec: 23350.414788\n",
            "Epoch Step: 2200 Loss: 22.197750 Tokens per Sec: 23619.179062\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years , i was just one of the other joy of joy .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father listened to his little , <unk> radio <unk> the <unk> of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he looked very happy , which was pretty much unusual , which was the news of the most beautiful <unk> .\n",
            "\n",
            "Validation perplexity: 11.764341\n",
            "Epoch 8\n",
            "Epoch Step: 200 Loss: 17.139458 Tokens per Sec: 23013.601102\n",
            "Epoch Step: 400 Loss: 52.297882 Tokens per Sec: 23740.098632\n",
            "Epoch Step: 600 Loss: 55.019089 Tokens per Sec: 23753.497250\n",
            "Epoch Step: 800 Loss: 27.937050 Tokens per Sec: 23506.085281\n",
            "Epoch Step: 1000 Loss: 11.297402 Tokens per Sec: 23761.678089\n",
            "Epoch Step: 1200 Loss: 12.249145 Tokens per Sec: 23776.672587\n",
            "Epoch Step: 1400 Loss: 35.790833 Tokens per Sec: 23685.089931\n",
            "Epoch Step: 1600 Loss: 37.545628 Tokens per Sec: 23736.770595\n",
            "Epoch Step: 1800 Loss: 41.916290 Tokens per Sec: 23421.349483\n",
            "Epoch Step: 2000 Loss: 15.639906 Tokens per Sec: 23764.074369\n",
            "Epoch Step: 2200 Loss: 28.221344 Tokens per Sec: 23851.036110\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years , i was a director of the <unk> <unk> joy .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father listened to his little , <unk> radio <unk> the <unk> .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he looked very happy , which was very unusual , which was pretty unusual , because they were <unk> the news .\n",
            "\n",
            "Validation perplexity: 11.660102\n",
            "Epoch 9\n",
            "Epoch Step: 200 Loss: 29.302559 Tokens per Sec: 22698.504308\n",
            "Epoch Step: 400 Loss: 22.215946 Tokens per Sec: 23599.251074\n",
            "Epoch Step: 600 Loss: 38.046879 Tokens per Sec: 23549.321643\n",
            "Epoch Step: 800 Loss: 22.630915 Tokens per Sec: 23640.399290\n",
            "Epoch Step: 1000 Loss: 13.586745 Tokens per Sec: 23265.704253\n",
            "Epoch Step: 1200 Loss: 17.694233 Tokens per Sec: 23234.948139\n",
            "Epoch Step: 1400 Loss: 15.316023 Tokens per Sec: 23403.373870\n",
            "Epoch Step: 1600 Loss: 2.642834 Tokens per Sec: 23356.165336\n",
            "Epoch Step: 1800 Loss: 32.956776 Tokens per Sec: 23241.280207\n",
            "Epoch Step: 2000 Loss: 25.353636 Tokens per Sec: 23045.066308\n",
            "Epoch Step: 2200 Loss: 53.733532 Tokens per Sec: 23475.962750\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years , i was going to be one of the morning of joy of joy .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father listened to his little , <unk> radio <unk> the <unk> .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he looked very happy , which was unusual about that , then , in the same time , it was pretty much more likely to <unk> the news .\n",
            "\n",
            "Validation perplexity: 11.977173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eXUhTLeBgCN",
        "outputId": "849833f4-75b8-4a1c-c04d-a9000e9eec4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plot_perplexity(dev_perplexities)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeqVsNutBvhx"
      },
      "source": [
        "## Prediction and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JYJQlHvMSvf",
        "outputId": "7c14b181-cb2c-4098-cf5c-a31981f404e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#!pip install torch sacrebleu"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/c4/8e948f601a4f9609e8b2b58f31966cb13cf17b940b82aa3e767f01c42c52/sacrebleu-1.4.14-py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 30kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 40kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 51kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 61kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Installing collected packages: portalocker, sacrebleu\n",
            "Successfully installed portalocker-2.0.0 sacrebleu-1.4.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVyfxdAOBuzW"
      },
      "source": [
        "import sacrebleu"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6MyX39DBu9x",
        "outputId": "7bcfd674-37b2-491a-a0ce-a290da3a2262",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# this should result in a perfect BLEU of 100%\n",
        "hypotheses = [\"this is a test ok \"]\n",
        "references = [\"this is a test ok \"]\n",
        "bleu = sacrebleu.raw_corpus_bleu(hypotheses, [references], .01).score\n",
        "print(bleu)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100.00000000000004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoMmS_qqBu6Z",
        "outputId": "ddbcbedb-9df4-46dd-afdb-f791bcf57036",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# here the BLEU score will be lower, because some n-grams won't match\n",
        "hypotheses = [\"this is a test ok \"]\n",
        "references = [\"this is a fest ok \"]\n",
        "bleu = sacrebleu.raw_corpus_bleu(hypotheses, [references], .01).score\n",
        "print(bleu)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16.068568378893037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zlatr-tuCJ8z"
      },
      "source": [
        "## Translate the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf-e_4unBu30"
      },
      "source": [
        "hypotheses = []\n",
        "alphas = []  # save the last attention scores\n",
        "for batch in valid_iter:\n",
        "  batch = rebatch(PAD_INDEX, batch)\n",
        "  pred, attention = greedy_decode(\n",
        "    model, batch.src, batch.src_mask, batch.src_lengths, max_len=25,\n",
        "    sos_index=TRG.vocab.stoi[SOS_TOKEN],\n",
        "    eos_index=TRG.vocab.stoi[EOS_TOKEN])\n",
        "  hypotheses.append(pred)\n",
        "  alphas.append(attention)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1szp8UUABf_x",
        "outputId": "a85afeb7-b2c9-4283-e06a-e8ee63273a06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# we will still need to convert the indices to actual words!\n",
        "hypotheses[0]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  70,   11,   24, 1460,  103,    5,   11,   24,   63,    8,   38,\n",
              "         40,   10,    6,  690,   10, 1806,   10, 1806,    4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3zQbQxsCS1b",
        "outputId": "f866e311-5df1-4b22-9bd6-ce8399a275bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hypotheses = [lookup_words(x, TRG.vocab) for x in hypotheses]\n",
        "hypotheses[0]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['when',\n",
              " 'i',\n",
              " 'was',\n",
              " '11',\n",
              " 'years',\n",
              " ',',\n",
              " 'i',\n",
              " 'was',\n",
              " 'going',\n",
              " 'to',\n",
              " 'be',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'morning',\n",
              " 'of',\n",
              " 'joy',\n",
              " 'of',\n",
              " 'joy',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogXYdh08CS-y",
        "outputId": "e8945b9f-f1f4-460f-9a84-236cddcd77ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# finally, the SacreBLEU raw scorer requires string input, so we convert the lists to strings\n",
        "hypotheses = [\" \".join(x) for x in hypotheses]\n",
        "print(len(hypotheses))\n",
        "print(hypotheses[0])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "690\n",
            "w   h   e   n       i       w   a   s       1   1       y   e   a   r   s       ,       i       w   a   s       g   o   i   n   g       t   o       b   e       o   n   e       o   f       t   h   e       m   o   r   n   i   n   g       o   f       j   o   y       o   f       j   o   y       .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnokVQ8pCa55"
      },
      "source": [
        "## Attention Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX4mlIjPCY15"
      },
      "source": [
        "def plot_heatmap(src, trg, scores):\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    heatmap = ax.pcolor(scores, cmap='viridis')\n",
        "\n",
        "    ax.set_xticklabels(trg, minor=False, rotation='vertical')\n",
        "    ax.set_yticklabels(src, minor=False)\n",
        "\n",
        "    # put the major ticks at the middle of each cell\n",
        "    # and the x-ticks on top\n",
        "    ax.xaxis.tick_top()\n",
        "    ax.set_xticks(np.arange(scores.shape[1]) + 0.5, minor=False)\n",
        "    ax.set_yticks(np.arange(scores.shape[0]) + 0.5, minor=False)\n",
        "    ax.invert_yaxis()\n",
        "\n",
        "    plt.colorbar(heatmap)\n",
        "    plt.show()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSmLkU1ACZAz",
        "outputId": "7950e53c-6326-4f50-ffc6-584263af656c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "# This plots a chosen sentence, for which we saved the attention scores above.\n",
        "idx = 5\n",
        "src = valid_data[idx].src + [\"</s>\"]\n",
        "trg = valid_data[idx].trg + [\"</s>\"]\n",
        "pred = hypotheses[idx].split() + [\"</s>\"]\n",
        "pred_att = alphas[idx][0].T[:, :len(pred)]\n",
        "print(\"src\", src)\n",
        "print(\"ref\", trg)\n",
        "print(\"pred\", pred)\n",
        "plot_heatmap(src, pred, pred_att)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src ['\"', 'jetzt', 'kannst', 'du', 'auf', 'eine', 'richtige', 'schule', 'gehen', ',', '\"', 'sagte', 'er', '.', '</s>']\n",
            "ref ['\"', 'you', 'can', 'go', 'to', 'a', 'real', 'school', 'now', ',', '\"', 'he', 'said', '.', '</s>']\n",
            "pred ['\"', 'n', 'o', 'w', 'y', 'o', 'u', 'c', 'a', 'n', 'g', 'o', 't', 'o', 'a', 'r', 'i', 'g', 'h', 't', 's', 'c', 'h', 'o', 'o', 'l', ',', '\"', 'h', 'e', 's', 'a', 'i', 'd', '.', '</s>']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxGw12sBCY9w"
      },
      "source": [
        "torch.save(model, f'{SAVED_MODELS_DIR}/attention_transformer.pt')"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIpcFxcdKJfk"
      },
      "source": [
        "loaded_model = torch.load(f'{SAVED_MODELS_DIR}/attention_transformer.pt')"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA2v-KONALig"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}